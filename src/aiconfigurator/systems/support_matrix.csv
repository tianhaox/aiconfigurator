Model,System,Backend,Version,Mode,Status,ErrMsg
DEEPSEEK_V3,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
DEEPSEEK_V3,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
DEEPSEEK_V3,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
DEEPSEEK_V3,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
DEEPSEEK_V3,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
DEEPSEEK_V3,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
DEEPSEEK_V3,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
DEEPSEEK_V3,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
DEEPSEEK_V3,h100_sxm,sglang,0.5.6.post2,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 412, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 186, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 99, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 421, in query\n    assert self._attention_tp_size == 1 or self._attention_dp_size == 1, (\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n"
DEEPSEEK_V3,h100_sxm,sglang,0.5.6.post2,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 421, in query\n    assert self._attention_tp_size == 1 or self._attention_dp_size == 1, (\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: We don't enable the path for SGLang to support TP>1 and DP>1 for attn simultaneously\n"
DEEPSEEK_V3,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 530, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 530, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
DEEPSEEK_V3,h100_sxm,vllm,0.12.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 858, in validate\n    raise NotImplementedError(""AIConfigurator does not yet support DEEPSEEK models for VLLM backend."")\nNotImplementedError: AIConfigurator does not yet support DEEPSEEK models for VLLM backend.\n"
DEEPSEEK_V3,h100_sxm,vllm,0.12.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 858, in validate\n    raise NotImplementedError(""AIConfigurator does not yet support DEEPSEEK models for VLLM backend."")\nNotImplementedError: AIConfigurator does not yet support DEEPSEEK models for VLLM backend.\n"
DEEPSEEK_V3,h200_sxm,sglang,0.5.6.post2,agg,PASS,
DEEPSEEK_V3,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
DEEPSEEK_V3,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
DEEPSEEK_V3,h200_sxm,vllm,0.12.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 858, in validate\n    raise NotImplementedError(""AIConfigurator does not yet support DEEPSEEK models for VLLM backend."")\nNotImplementedError: AIConfigurator does not yet support DEEPSEEK models for VLLM backend.\n"
DEEPSEEK_V3,h200_sxm,vllm,0.12.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 858, in validate\n    raise NotImplementedError(""AIConfigurator does not yet support DEEPSEEK models for VLLM backend."")\nNotImplementedError: AIConfigurator does not yet support DEEPSEEK models for VLLM backend.\n"
DEEPSEEK_V3,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 412, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 186, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 99, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 651, in query\n    result = database.query_context_mla(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2909, in query_context_mla\n    raise PerfDataNotAvailableError(\naiconfigurator.sdk.perf_database.PerfDataNotAvailableError: Context MLA perf table is missing for system='l40s', backend='sglang', version='0.5.5.post3'. Please use HYBRID or EMPIRICAL database mode, or provide the data file.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: Context MLA perf table is missing for system='l40s', backend='sglang', version='0.5.5.post3'. Please use HYBRID or EMPIRICAL database mode, or provide the data file.\n"
DEEPSEEK_V3,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 651, in query\n    result = database.query_context_mla(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2909, in query_context_mla\n    raise PerfDataNotAvailableError(\naiconfigurator.sdk.perf_database.PerfDataNotAvailableError: Context MLA perf table is missing for system='l40s', backend='sglang', version='0.5.5.post3'. Please use HYBRID or EMPIRICAL database mode, or provide the data file.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: Context MLA perf table is missing for system='l40s', backend='sglang', version='0.5.5.post3'. Please use HYBRID or EMPIRICAL database mode, or provide the data file.\n"
DEEPSEEK_V3,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
DEEPSEEK_V3,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,b200_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,b200_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,gb200_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,gb200_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,sglang,0.5.6.post2,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 412, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 186, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 99, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,sglang,0.5.6.post2,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,vllm,0.12.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h100_sxm,vllm,0.12.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,sglang,0.5.6.post2,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 412, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 186, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 99, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,sglang,0.5.6.post2,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,vllm,0.12.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,h200_sxm,vllm,0.12.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_120B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
GPT_OSS_120B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
GPT_OSS_120B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
GPT_OSS_120B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
GPT_OSS_20B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,b200_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,b200_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,gb200_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,gb200_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,sglang,0.5.6.post2,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 412, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 186, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 99, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,sglang,0.5.6.post2,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,vllm,0.12.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h100_sxm,vllm,0.12.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,sglang,0.5.6.post2,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 45, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 412, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 186, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/sglang_backend.py"", line 99, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,sglang,0.5.6.post2,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.2.0rc5,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,trtllm,1.2.0rc5,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,vllm,0.12.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/vllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,h200_sxm,vllm,0.12.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 562, in query\n    result = database.query_context_attention(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2664, in query_context_attention\n    result = self._interp_3d(n, full_s, b, attention_dict, ""cubic"")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2286, in _interp_3d\n    latency = self._interp_2d_1d(x, y, z, latency_data, method)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2356, in _interp_2d_1d\n    x_left, x_right = self._nearest_1d_point_helper(x, list(data.keys()))\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
GPT_OSS_20B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
GPT_OSS_20B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
GPT_OSS_20B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
GPT_OSS_20B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA2_13B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_13B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_13B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_13B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_13B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_13B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_13B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_13B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_13B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_13B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_13B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA2_13B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA2_13B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_13B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_13B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_13B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_13B,h100_sxm,vllm,0.12.0,agg,PASS,
LLAMA2_13B,h100_sxm,vllm,0.12.0,disagg,PASS,
LLAMA2_13B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA2_13B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_13B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_13B,h200_sxm,vllm,0.12.0,agg,PASS,
LLAMA2_13B,h200_sxm,vllm,0.12.0,disagg,PASS,
LLAMA2_13B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA2_13B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA2_13B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA2_13B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA2_70B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_70B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_70B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_70B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_70B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_70B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_70B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_70B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_70B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_70B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_70B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA2_70B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA2_70B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_70B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_70B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_70B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_70B,h100_sxm,vllm,0.12.0,agg,PASS,
LLAMA2_70B,h100_sxm,vllm,0.12.0,disagg,PASS,
LLAMA2_70B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA2_70B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_70B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_70B,h200_sxm,vllm,0.12.0,agg,PASS,
LLAMA2_70B,h200_sxm,vllm,0.12.0,disagg,PASS,
LLAMA2_70B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA2_70B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA2_70B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA2_70B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA2_7B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA2_7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA2_7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_7B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_7B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA2_7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA2_7B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_7B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_7B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA2_7B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA2_7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_7B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_7B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_7B,h100_sxm,vllm,0.12.0,agg,PASS,
LLAMA2_7B,h100_sxm,vllm,0.12.0,disagg,PASS,
LLAMA2_7B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA2_7B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA2_7B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA2_7B,h200_sxm,vllm,0.12.0,agg,PASS,
LLAMA2_7B,h200_sxm,vllm,0.12.0,disagg,PASS,
LLAMA2_7B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA2_7B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA2_7B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA2_7B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA3.1_405B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 143, in agg_pareto\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_405B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 530, in _get_summary_df\n    f""No results found for any parallel configuration. Showing last exception: {exceptions[-1]}""\n                                                                                ~~~~~~~~~~^^^^\nIndexError: list index out of range\n"
LLAMA3.1_405B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_405B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_405B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_405B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_405B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_405B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_405B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_405B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_405B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA3.1_405B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_405B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_405B,h100_sxm,vllm,0.12.0,agg,PASS,
LLAMA3.1_405B,h100_sxm,vllm,0.12.0,disagg,PASS,
LLAMA3.1_405B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA3.1_405B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_405B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_405B,h200_sxm,vllm,0.12.0,agg,PASS,
LLAMA3.1_405B,h200_sxm,vllm,0.12.0,disagg,PASS,
LLAMA3.1_405B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA3.1_405B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA3.1_405B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA3.1_405B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA3.1_70B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA3.1_70B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_70B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_70B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_70B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_70B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_70B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_70B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_70B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_70B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_70B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA3.1_70B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_70B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_70B,h100_sxm,vllm,0.12.0,agg,PASS,
LLAMA3.1_70B,h100_sxm,vllm,0.12.0,disagg,PASS,
LLAMA3.1_70B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA3.1_70B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_70B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_70B,h200_sxm,vllm,0.12.0,agg,PASS,
LLAMA3.1_70B,h200_sxm,vllm,0.12.0,disagg,PASS,
LLAMA3.1_70B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA3.1_70B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA3.1_70B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA3.1_70B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA3.1_8B,a100_sxm,trtllm,1.0.0,agg,PASS,
LLAMA3.1_8B,a100_sxm,trtllm,1.0.0,disagg,PASS,
LLAMA3.1_8B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_8B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_8B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_8B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_8B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
LLAMA3.1_8B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
LLAMA3.1_8B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_8B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_8B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA3.1_8B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_8B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_8B,h100_sxm,vllm,0.12.0,agg,PASS,
LLAMA3.1_8B,h100_sxm,vllm,0.12.0,disagg,PASS,
LLAMA3.1_8B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
LLAMA3.1_8B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
LLAMA3.1_8B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
LLAMA3.1_8B,h200_sxm,vllm,0.12.0,agg,PASS,
LLAMA3.1_8B,h200_sxm,vllm,0.12.0,disagg,PASS,
LLAMA3.1_8B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA3.1_8B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
LLAMA3.1_8B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
LLAMA3.1_8B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
MOE_Mixtral8x22B,a100_sxm,trtllm,1.0.0,agg,PASS,
MOE_Mixtral8x22B,a100_sxm,trtllm,1.0.0,disagg,PASS,
MOE_Mixtral8x22B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x22B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x22B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
MOE_Mixtral8x22B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
MOE_Mixtral8x22B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x22B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x22B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
MOE_Mixtral8x22B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
MOE_Mixtral8x22B,h100_sxm,vllm,0.12.0,agg,PASS,
MOE_Mixtral8x22B,h100_sxm,vllm,0.12.0,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
MOE_Mixtral8x22B,h200_sxm,vllm,0.12.0,agg,PASS,
MOE_Mixtral8x22B,h200_sxm,vllm,0.12.0,disagg,PASS,
MOE_Mixtral8x22B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
MOE_Mixtral8x22B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
MOE_Mixtral8x22B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
MOE_Mixtral8x22B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
MOE_Mixtral8x7B,a100_sxm,trtllm,1.0.0,agg,PASS,
MOE_Mixtral8x7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
MOE_Mixtral8x7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x7B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
MOE_Mixtral8x7B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
MOE_Mixtral8x7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
MOE_Mixtral8x7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
MOE_Mixtral8x7B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
MOE_Mixtral8x7B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
MOE_Mixtral8x7B,h100_sxm,vllm,0.12.0,agg,PASS,
MOE_Mixtral8x7B,h100_sxm,vllm,0.12.0,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
MOE_Mixtral8x7B,h200_sxm,vllm,0.12.0,agg,PASS,
MOE_Mixtral8x7B,h200_sxm,vllm,0.12.0,disagg,PASS,
MOE_Mixtral8x7B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
MOE_Mixtral8x7B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
MOE_Mixtral8x7B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
MOE_Mixtral8x7B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
Nemotron_super_v1.1,a100_sxm,trtllm,1.0.0,agg,PASS,
Nemotron_super_v1.1,a100_sxm,trtllm,1.0.0,disagg,PASS,
Nemotron_super_v1.1,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
Nemotron_super_v1.1,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
Nemotron_super_v1.1,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
Nemotron_super_v1.1,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
Nemotron_super_v1.1,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
Nemotron_super_v1.1,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
Nemotron_super_v1.1,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
Nemotron_super_v1.1,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,sglang,0.5.6.post2,agg,PASS,
Nemotron_super_v1.1,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
Nemotron_super_v1.1,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
Nemotron_super_v1.1,h100_sxm,vllm,0.12.0,agg,PASS,
Nemotron_super_v1.1,h100_sxm,vllm,0.12.0,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,sglang,0.5.6.post2,agg,PASS,
Nemotron_super_v1.1,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
Nemotron_super_v1.1,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
Nemotron_super_v1.1,h200_sxm,vllm,0.12.0,agg,PASS,
Nemotron_super_v1.1,h200_sxm,vllm,0.12.0,disagg,PASS,
Nemotron_super_v1.1,l40s,sglang,0.5.5.post3,agg,PASS,
Nemotron_super_v1.1,l40s,sglang,0.5.5.post3,disagg,PASS,
Nemotron_super_v1.1,l40s,trtllm,1.0.0,agg,PASS,
Nemotron_super_v1.1,l40s,trtllm,1.0.0,disagg,PASS,
QWEN2.5_1.5B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_1.5B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_1.5B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_1.5B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_1.5B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_1.5B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_1.5B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_1.5B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_1.5B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_1.5B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN2.5_1.5B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_1.5B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_1.5B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN2.5_1.5B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN2.5_1.5B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_1.5B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_1.5B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN2.5_1.5B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN2.5_1.5B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN2.5_1.5B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN2.5_1.5B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN2.5_1.5B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN2.5_32B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_32B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_32B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_32B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_32B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_32B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_32B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_32B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_32B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_32B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_32B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN2.5_32B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_32B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_32B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN2.5_32B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN2.5_32B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN2.5_32B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_32B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_32B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN2.5_32B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN2.5_32B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN2.5_32B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN2.5_32B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN2.5_32B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN2.5_72B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_72B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_72B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_72B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_72B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_72B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_72B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_72B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_72B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_72B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_72B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN2.5_72B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_72B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_72B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN2.5_72B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN2.5_72B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN2.5_72B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_72B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_72B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN2.5_72B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN2.5_72B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN2.5_72B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN2.5_72B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN2.5_72B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN2.5_7B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN2.5_7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN2.5_7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_7B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_7B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN2.5_7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN2.5_7B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_7B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_7B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN2.5_7B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_7B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_7B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN2.5_7B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN2.5_7B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN2.5_7B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN2.5_7B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN2.5_7B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN2.5_7B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN2.5_7B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN2.5_7B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN2.5_7B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN2.5_7B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_0.6B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_0.6B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_0.6B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_0.6B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_0.6B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_0.6B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_0.6B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_0.6B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_0.6B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_0.6B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_0.6B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_0.6B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_0.6B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_0.6B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN3_0.6B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_0.6B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_0.6B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_0.6B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_0.6B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN3_0.6B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_0.6B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_0.6B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_0.6B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_0.6B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_1.7B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_1.7B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_1.7B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_1.7B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_1.7B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_1.7B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_1.7B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_1.7B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_1.7B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_1.7B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_1.7B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_1.7B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_1.7B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_1.7B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN3_1.7B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_1.7B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_1.7B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_1.7B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_1.7B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN3_1.7B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_1.7B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_1.7B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_1.7B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_1.7B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_235B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_235B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_235B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_235B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_235B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_235B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_235B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_235B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_235B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_235B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_235B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_235B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_235B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_235B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_235B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_235B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_235B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN3_235B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_235B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_235B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_235B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_235B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN3_235B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_235B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_235B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_235B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_235B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_30B_A3B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,b200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,b200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_30B_A3B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_30B_A3B,gb200_sxm,trtllm,1.0.0rc6,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,gb200_sxm,trtllm,1.0.0rc6,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_30B_A3B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_30B_A3B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_30B_A3B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_30B_A3B,h100_sxm,trtllm,1.0.0rc3,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,1.0.0rc3,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_30B_A3B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_30B_A3B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_30B_A3B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN3_30B_A3B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_30B_A3B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_30B_A3B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_30B_A3B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN3_30B_A3B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_30B_A3B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_30B_A3B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_30B_A3B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_30B_A3B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_32B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_32B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_32B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_32B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_32B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_32B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_32B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_32B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_32B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_32B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_32B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_32B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_32B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_32B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_32B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_32B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_32B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN3_32B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_32B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_32B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_32B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_32B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN3_32B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_32B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_32B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_32B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_32B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_480B,a100_sxm,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 47, in run_agg\n    summary = self._agg_cache[isl][osl][b][ctx_tokens]\n              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 4000\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 106, in agg_pareto\n    summary = sess.find_best_agg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 99, in find_best_agg_result_under_constraints\n    return self._backend.find_best_agg_result_under_constraints(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 413, in find_best_agg_result_under_constraints\n    summary = self.run_agg(\n              ^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 187, in run_agg\n    mix_step_latency_ms, mix_step_energy_wms = _get_mix_step_latency(\n                                               ^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/trtllm_backend.py"", line 101, in _get_mix_step_latency\n    summary = self.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1275, in run\n    result = self.run_agg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1097, in run_agg\n    result_df = pa.agg_pareto(\n                ^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 142, in agg_pareto\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_480B,a100_sxm,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 507, in _get_summary_df\n    summary = sess.run_static(\n              ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 66, in run_static\n    return self._backend.run_static(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 153, in run_static\n    context_latency_dict, context_energy_wms_dict = _run_context(batch_size, isl, prefix)\n                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/backends/base_backend.py"", line 81, in _run_context\n    result = op.query(database, x=x, batch_size=batch_size, beam_width=1, s=isl, prefix=prefix)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/operations.py"", line 223, in query\n    result = database.query_moe(\n             ^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 3795, in query_moe\n    num_left, num_right = self._nearest_1d_point_helper(\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/perf_database.py"", line 2147, in _nearest_1d_point_helper\n    assert values is not None and len(values) >= 2, ""values is None or len(values) < 2""\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: values is None or len(values) < 2\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 118, in run_single_test\n    result = runner.run(task_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1277, in run\n    result = self.run_disagg(task_config.config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 1243, in run_disagg\n    result_df = pa.disagg_pareto(\n                ^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/pareto_analysis.py"", line 248, in disagg_pareto\n    summary = disagg_sess.find_best_disagg_result_under_constraints(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 667, in find_best_disagg_result_under_constraints\n    prefill_summary_df = _get_summary_df(\n                         ^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/inference_session.py"", line 529, in _get_summary_df\n    raise RuntimeError(\nRuntimeError: No results found for any parallel configuration. Showing last exception: values is None or len(values) < 2\n"
QWEN3_480B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_480B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_480B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_480B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_480B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_480B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_480B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_480B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_480B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_480B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_480B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_480B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_480B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_480B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_480B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN3_480B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_480B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_480B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_480B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_480B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN3_480B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_480B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_480B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_480B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_480B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_8B,a100_sxm,trtllm,1.0.0,agg,PASS,
QWEN3_8B,a100_sxm,trtllm,1.0.0,disagg,PASS,
QWEN3_8B,b200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_8B,b200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_8B,b200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_8B,b200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_8B,gb200_sxm,trtllm,1.0.0rc6,agg,PASS,
QWEN3_8B,gb200_sxm,trtllm,1.0.0rc6,disagg,PASS,
QWEN3_8B,gb200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_8B,gb200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_8B,h100_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_8B,h100_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_8B,h100_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_8B,h100_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_8B,h100_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_8B,h100_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_8B,h100_sxm,vllm,0.12.0,agg,PASS,
QWEN3_8B,h100_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_8B,h200_sxm,sglang,0.5.6.post2,agg,PASS,
QWEN3_8B,h200_sxm,sglang,0.5.6.post2,disagg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.0.0rc3,agg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.0.0rc3,disagg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.2.0rc5,agg,PASS,
QWEN3_8B,h200_sxm,trtllm,1.2.0rc5,disagg,PASS,
QWEN3_8B,h200_sxm,vllm,0.12.0,agg,PASS,
QWEN3_8B,h200_sxm,vllm,0.12.0,disagg,PASS,
QWEN3_8B,l40s,sglang,0.5.5.post3,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_8B,l40s,sglang,0.5.5.post3,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='sglang', version='0.5.5.post3'. Supported moe modes: ['float16', 'fp8_block']\n"
QWEN3_8B,l40s,trtllm,1.0.0,agg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 922, in validate\n    _validate_worker_config(self.config.worker_config, validate_context=True, validate_generation=True)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
QWEN3_8B,l40s,trtllm,1.0.0,disagg,FAIL,"Traceback (most recent call last):\n  File ""tests/sdk/support_matrix/suppport_matrix.py"", line 114, in run_single_test\n    task_config = TaskConfig(**task_config_kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File ""src/aiconfigurator/sdk/task.py"", line 849, in __init__\n    self.validate()\n  File ""src/aiconfigurator/sdk/task.py"", line 924, in validate\n    _validate_worker_config(self.config.prefill_worker_config, validate_context=True, validate_generation=False)\n  File ""src/aiconfigurator/sdk/task.py"", line 912, in _validate_worker_config\n    _supported_or_raise(""moe"", moe_mode)\n  File ""src/aiconfigurator/sdk/task.py"", line 875, in _supported_or_raise\n    raise ValueError(\nValueError: Unsupported moe quant mode 'fp8' for system='l40s', backend='trtllm', version='1.0.0'. Supported moe modes: ['float16', 'w4afp8']\n"
