backend: pytorch

{% if is_moe is defined %}  # is_moe from sdk
moe_expert_parallel_size: {{ moe_expert_parallel_size }}
moe_tensor_parallel_size: {{ moe_tensor_parallel_size }}
{% endif %}

tensor_parallel_size: {{ tensor_parallel_size }}
pipeline_parallel_size: {{ pipeline_parallel_size }}
enable_attention_dp: {{ enable_attention_dp | default(false) }}
enable_chunked_prefill: {{ enable_chunked_prefill | default(false) }}

{% set _max_seq_len = build_config.max_seq_len | default(none) %}

max_batch_size: {{ build_config.max_batch_size }}
max_num_tokens: {{ build_config.max_num_tokens }}
{% if _max_seq_len is not none and _max_seq_len != '' %}
max_seq_len: {{ _max_seq_len }}
{% endif %}

kv_cache_config:
  enable_block_reuse: {{ kv_cache_config.enable_block_reuse | default(false) }}
  free_gpu_memory_fraction: {{ kv_cache_config.free_gpu_memory_fraction | default(0.80) }}  # Fraction for KVâ€‘cache
  {% if kv_cache_config.tokens_per_block is defined %}
  tokens_per_block: {{ kv_cache_config.tokens_per_block }}
  {% endif %}

{% if speculative_config.decoding_type is defined %}  # speculative decoding
speculative_config:
  decoding_type: {{ speculative_config.decoding_type }}
  {% if speculative_config.decoding_type == 'MTP' %}
  num_nextn_predict_layers: {{ num_nextn_predict_layers }}
  {% endif %}
{% endif %}
