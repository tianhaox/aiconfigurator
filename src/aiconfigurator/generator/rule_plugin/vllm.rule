prefill max_batch_size = (max_batch_size if max_batch_size else 1)
decode max_batch_size = (max_batch_size if max_batch_size else 128)


agg_prefill_decode gpus_per_worker = (tensor_parallel_size or 1) * (pipeline_parallel_size or 1) * (data_parallel_size or 1)

prefill max_num_tokens = (SlaConfig.isl or 0) + 1500
decode max_num_tokens = max_batch_size
agg max_num_tokens = (max_batch_size or 0) + (SlaConfig.isl or 0) + 1500

when (ModelConfig.prefix or 0) > 0:
    disable_prefix_cache = false

when (ModelConfig.nextn or 0) > 0:
    speculative_decoding_type = "mtp"
    num_nextn_predict_layers = ModelConfig.nextn

