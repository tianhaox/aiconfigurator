prefill max_batch_size = (max_batch_size if max_batch_size else 1)
agg_decode max_batch_size = (max_batch_size if max_batch_size else 128)

agg_prefill_decode max_prefill_tokens = SlaConfig.isl + 1500


agg_prefill_decode cuda_graph_batch_sizes = ((range(1, max_batch_size + 1) | list) if max_batch_size else [])

# GPUs per worker follow the same TP/PP/DP product that SGLang expects
agg_prefill_decode gpus_per_worker = (tensor_parallel_size or 1) * (pipeline_parallel_size or 1) * (data_parallel_size or 1)

agg_prefill_decode kv_cache_dtype = ("fp8_e5m2" if kv_cache_dtype == "fp8" else kv_cache_dtype)

when (ModelConfig.prefix or 0) > 0:
    disable_prefix_cache = false

when (ModelConfig.nextn or 0) > 0:
    speculative_decoding_type = "NEXTN"
    speculative_num_steps = ModelConfig.nextn
